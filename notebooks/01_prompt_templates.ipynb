{"cells":[{"cell_type":"markdown","id":"f0cbbdfe-e1aa-467c-b3ab-31cfc1291458","metadata":{"id":"f0cbbdfe-e1aa-467c-b3ab-31cfc1291458"},"source":["# Prompt Templates and Dynamic Prompts"]},{"cell_type":"markdown","id":"eeab7474-c5ee-4f37-9d48-7688314f1fe7","metadata":{"id":"eeab7474-c5ee-4f37-9d48-7688314f1fe7"},"source":["PromptTemplates in Langchain enables dynamic insertion of variables into standardized prompt structures."]},{"cell_type":"markdown","id":"89be3c8d-e61f-4d63-a496-b5d6580cdece","metadata":{"id":"89be3c8d-e61f-4d63-a496-b5d6580cdece"},"source":["A PromptTemplate is a blueprint for creating dynamic prompts. Instead of writing static\n","prompts, you create templates with placeholders (variables) that get filled in at runtime."]},{"cell_type":"markdown","source":["## Bootstrap"],"metadata":{"id":"qLxP5a5nM5hy"},"id":"qLxP5a5nM5hy"},{"cell_type":"markdown","source":["‚öì--- Before proceeding futher it is very important you do the following: --- üëæ\n","\n","Select the üóù (key) icon in the left pane and include your OpenAI Api key with Name as \"OPENAPI_KEY\" and value as the key, and grant it notebook access in order to be able to run this notebook."],"metadata":{"id":"i7DwKnekM8RS"},"id":"i7DwKnekM8RS"},{"cell_type":"markdown","id":"08eb5f2f-b486-41cf-9d7a-e84094988994","metadata":{"id":"08eb5f2f-b486-41cf-9d7a-e84094988994"},"source":["Run the below two cells in the order they are in, before running further cells. Wait till a number appears in place of '*' or '[ ]'. Below the cell you should see \"Ready. LangChain + OpenAI set up.\""]},{"cell_type":"code","source":["!pip install -q langchain langchain-openai langchain-community pydantic pypdf faiss-cpu"],"metadata":{"id":"qP1WT8CNNB0O"},"id":"qP1WT8CNNB0O","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"232664be-67b4-4758-b492-d5ac5f89178a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"232664be-67b4-4758-b492-d5ac5f89178a","executionInfo":{"status":"ok","timestamp":1756410331777,"user_tz":-330,"elapsed":9654,"user":{"displayName":"Vishvak","userId":"11352816944170122427"}},"outputId":"354421fa-c8ba-4ec5-fc5f-8780bff75557"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Ready: Prompt Templates with LCEL\n"]}],"source":["# Bootstrap: environment & model (same as earlier)\n","from google.colab import userdata\n","\n","key = userdata.get('OPENAI_API_KEY')  # returns None if not granted\n","if not key:\n","    raise RuntimeError(\"Set OPENAI_API_KEY in a .env file next to this notebook.\")\n","\n","from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder\n","from langchain_core.runnables import RunnableLambda\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_openai import ChatOpenAI\n","from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n","\n","llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, streaming=True, api_key=key)\n","\n","print(\"‚úÖ Ready: Prompt Templates with LCEL\")"]},{"cell_type":"markdown","id":"05b1f6a2-67f2-42a1-a292-7a2093f6c433","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"05b1f6a2-67f2-42a1-a292-7a2093f6c433"},"source":["## PromptTemplate"]},{"cell_type":"markdown","id":"fd80e1a8-bcbc-4350-ac60-a2a4cba52c5c","metadata":{"id":"fd80e1a8-bcbc-4350-ac60-a2a4cba52c5c"},"source":["The most basic prompt template in Langchain is `PromptTemplate`. You can use `PromptTemplates` of any kind in one of two ways. Using `.format` to fill the variable value or directly in a chain using `.invoke` by placing the template variable value in a dictionary with the variable name as the key."]},{"cell_type":"code","execution_count":null,"id":"6f902f97-7082-420d-b016-6b0775b34eef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6f902f97-7082-420d-b016-6b0775b34eef","executionInfo":{"status":"ok","timestamp":1756410337868,"user_tz":-330,"elapsed":1595,"user":{"displayName":"Vishvak","userId":"11352816944170122427"}},"outputId":"e8573c11-9441-496e-9667-321e1b3d60ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rendered Prompt:\n"," Summarize the following text in 2 sentences:\n","\n","LangChain lets you build LLM apps by composing prompt, model, and tools.\n","\n","--- Final Output ---\n","LangChain enables the creation of large language model (LLM) applications by integrating prompts, models, and various tools. This compositional approach simplifies the development process for building sophisticated LLM-based solutions.\n"]}],"source":["# Define a single-message text template\n","summary_tpl = PromptTemplate.from_template(\n","    \"Summarize the following text in 2 sentences:\\n\\n{text}\"\n",")\n","\n","# Use it standalone\n","prompt_text = summary_tpl.format(text=\"LangChain lets you build LLM apps by composing prompt, model, and tools.\")\n","print(\"Rendered Prompt:\\n\", prompt_text)\n","\n","# Use it in a chain (Prompt ‚Üí Model ‚Üí Parser)\n","summary_chain = summary_tpl | llm | StrOutputParser()\n","result = summary_chain.invoke({\"text\": \"LangChain lets you build LLM apps by composing prompt, model, and tools.\"})\n","\n","print(\"\\n--- Final Output ---\")\n","print(result)"]},{"cell_type":"markdown","id":"394d7cfb-00fa-4230-9664-25c256c418fc","metadata":{"id":"394d7cfb-00fa-4230-9664-25c256c418fc"},"source":["## ChatPromptTemplate"]},{"cell_type":"markdown","id":"312102b2-eece-4b1a-b07a-80a7ab80050a","metadata":{"id":"312102b2-eece-4b1a-b07a-80a7ab80050a"},"source":["ChatPromptTemplate is specifically designed for chat-based interactions. It handles the conversation structure with system messages, human messages, and AI messages, making it perfect for ChatGPT-style applications."]},{"cell_type":"markdown","id":"1d8f3357-29b0-4390-a655-0cb2c1321fbb","metadata":{"id":"1d8f3357-29b0-4390-a655-0cb2c1321fbb"},"source":["### Messages\n","\n","ChatPromptTemplate requires Messages as inputs. These Messages (also called Message roles) are used to define the speaker of each message in a conversation. For user the message is `HumanMessage`, for the LLM response `AIMessage`, for system message (more on this later) it is `SystemMessage`. There is also `ToolMessage` which represents the message by the tool called (Tool-calling)."]},{"cell_type":"code","execution_count":null,"id":"a82cd8e0-c8d7-4ce6-a4c2-1d077239f375","metadata":{"id":"a82cd8e0-c8d7-4ce6-a4c2-1d077239f375"},"outputs":[],"source":["chat_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a precise assistant that uses markdown bullets.\"),\n","    (\"user\", \"Explain {topic} in 3 short bullets.\")\n","])\n","\n","chain = chat_prompt | llm | StrOutputParser()\n","print(\"\\n--- Final Output ---\")\n","print(chain.invoke({\"topic\": \"Prompt Templates in LangChain\"}))"]},{"cell_type":"markdown","id":"199a073f-44c9-43c6-9422-231c7118dace","metadata":{"id":"199a073f-44c9-43c6-9422-231c7118dace"},"source":["## Chat history and Messages placeholder"]},{"cell_type":"markdown","id":"b61774d2-7d58-4bb5-a521-0287dba40074","metadata":{"id":"b61774d2-7d58-4bb5-a521-0287dba40074"},"source":["ChatPromptTemplate accepts a list of messages as input making them perfect for Conversational chatbots with chat history."]},{"cell_type":"markdown","id":"ee43555c-ab73-47b2-9926-bbb333d1beda","metadata":{"id":"ee43555c-ab73-47b2-9926-bbb333d1beda"},"source":["For this purpose we'll be using `MessagesPlaceholder` which allow for dynamic injection of messages into a prompt.\n","\n","### How it works\n","\n","MessagesPlaceholder is used within a `ChatPromptTemplate.from_messages()` call. It takes a single argument: the variable name that will be used to pass in the list of messages.\n","\n","Let's see how we can use `MessagesPlaceholder` for Chat history."]},{"cell_type":"code","execution_count":null,"id":"7f730822-2a26-4ed8-a12e-832d92ef757f","metadata":{"id":"7f730822-2a26-4ed8-a12e-832d92ef757f"},"outputs":[],"source":["# Define the chat prompt template with a placeholder for history\n","messages_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful assistant.\"),\n","    MessagesPlaceholder(variable_name=\"chat_history\"),\n","    (\"human\", \"{user_input}\")\n","])\n","\n","# Let's create a chat history list\n","chat_history = [\n","    HumanMessage(content=\"What's the capital of France?\"),\n","    AIMessage(content=\"The capital of France is Paris.\")\n","]\n","\n","messages_chain = messages_prompt | llm | StrOutputParser()\n","\n","result = messages_chain.invoke({\n","    \"chat_history\": chat_history,\n","    \"user_input\": \"What's the famous food in the city?\"\n","})\n","\n","print(result)"]},{"cell_type":"markdown","id":"7344dc3a-9799-4b9f-bd89-2ec21fa1a6b9","metadata":{"id":"7344dc3a-9799-4b9f-bd89-2ec21fa1a6b9"},"source":["Now, without previous context for the prompt \"What's the most famous food in the city?\" you wouldn't be getting the response you'd expect."]},{"cell_type":"markdown","id":"98731aaf-644b-4407-aede-e79dddcd08ff","metadata":{"id":"98731aaf-644b-4407-aede-e79dddcd08ff"},"source":["## Few shot prompts"]},{"cell_type":"markdown","id":"7e638e73-4fb0-4509-b4d9-6c948931abd6","metadata":{"id":"7e638e73-4fb0-4509-b4d9-6c948931abd6"},"source":["Few shot prompt is a famous prompt that shows examples of the desired instruction-response pairs for the AI to mimic. We can achieve this Langchain in many ways but Langchain has an inbuilt PromptTemplate for the same."]},{"cell_type":"code","execution_count":null,"id":"5e4e4e64-c83e-4fc8-b980-e78015936bb5","metadata":{"id":"5e4e4e64-c83e-4fc8-b980-e78015936bb5"},"outputs":[],"source":["sentiment_examples = [\n","    {\n","        \"text\": \"I absolutely love this product! It exceeded all my expectations.\",\n","        \"sentiment\": \"Positive\",\n","        \"confidence\": \"High\"\n","    },\n","    {\n","        \"text\": \"The service was okay, nothing special but not terrible either.\",\n","        \"sentiment\": \"Neutral\",\n","        \"confidence\": \"Medium\"\n","    },\n","    {\n","        \"text\": \"Completely disappointed with this purchase. Total waste of money.\",\n","        \"sentiment\": \"Negative\",\n","        \"confidence\": \"High\"\n","    }\n","]\n","\n","example_template = PromptTemplate(\n","    input_variables=[\"text\", \"sentiment\", \"confidence\"],\n","    template=\"Text: {text}\\nSentiment: {sentiment}\\nConfidence: {confidence}\"\n",")\n","\n","sentiment_few_shot = FewShotPromptTemplate(\n","    examples=sentiment_examples,\n","    example_prompt=example_template,\n","    prefix=\"Analyze the sentiment of the following texts. For each text, provide the sentiment (Positive/Negative/Neutral) and confidence level (High/Medium/Low).\\n\\nExamples:\",\n","    suffix=\"\\nText: {input_text}\\n\",\n","    input_variables=[\"input_text\"]\n",")\n","\n","sentiment_chain = sentiment_few_shot | llm | StrOutputParser()\n","\n","print(sentiment_chain.invoke({\"input_text\":\"The movie was quite entertaining, though the ending felt rushed.\"}))"]},{"cell_type":"markdown","id":"8f69b0fb-f725-4eec-b6a7-ed6f51d64e4d","metadata":{"id":"8f69b0fb-f725-4eec-b6a7-ed6f51d64e4d"},"source":["### How it works\n","\n","You need a few examples that are a list of dictionaries. You need to create a Prompt template based on the list of dictionaries. When the llm is invoked with this template, based on the template and the example list, if the list contains n dictionaries n prompts are created in the structure of the `PromptTemplate` and then added to the input prompt (`FewShotPromptTemplate`). User query and additional context can be added before or after this using prefix or suffix."]},{"cell_type":"markdown","id":"bbb7f2bd-a55c-43f2-9d4b-7c5cba8f38ed","metadata":{"id":"bbb7f2bd-a55c-43f2-9d4b-7c5cba8f38ed"},"source":["## Validation of Prompt templates"]},{"cell_type":"markdown","id":"c5417157-8ad1-4f97-876f-56470413845b","metadata":{"id":"c5417157-8ad1-4f97-876f-56470413845b"},"source":["Langchain validates required variables at render time."]},{"cell_type":"code","execution_count":null,"id":"768f77c7-6626-4407-b95e-b7b4f2aaad82","metadata":{"id":"768f77c7-6626-4407-b95e-b7b4f2aaad82","outputId":"252b72df-cadc-46fd-af53-4647f333f358"},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation error: 'role'\n"]}],"source":["try:\n","    bad = PromptTemplate.from_template(\"Hello {name}, you are {role}.\")\n","    print(bad.format(name=\"Ada\"))  # missing 'role'\n","except Exception as e:\n","    print(\"Validation error:\", e)"]},{"cell_type":"markdown","id":"935014e1-022d-488c-a23e-b5ee17b16547","metadata":{"id":"935014e1-022d-488c-a23e-b5ee17b16547"},"source":["This way you can validate whether or not a prompt is receiving the required values when building applications."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}