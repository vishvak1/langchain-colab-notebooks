{"cells":[{"cell_type":"markdown","id":"eb73744f-bbc1-4d69-9376-cdc0662d9dfa","metadata":{"id":"eb73744f-bbc1-4d69-9376-cdc0662d9dfa"},"source":["# Output Parsers"]},{"cell_type":"markdown","id":"5ce1b254-e32f-48ee-aefe-287fa5322ae8","metadata":{"id":"5ce1b254-e32f-48ee-aefe-287fa5322ae8"},"source":["Output Parsers convert the model‚Äôs raw text or message into a clean, structured Python value (string, list, dict/JSON, Pydantic object, etc.). They make your chains reliable, testable, and easy to compose."]},{"cell_type":"markdown","id":"41559677-776e-4f8b-a5f2-bcda6e1591a0","metadata":{"id":"41559677-776e-4f8b-a5f2-bcda6e1591a0"},"source":["I think of it as taking a language like English and producing structured outputs with it. This is standardizing outputs using an input language as verbose and unstructured as English."]},{"cell_type":"markdown","id":"44291cde-79d0-4926-a0c6-738de5304b09","metadata":{"id":"44291cde-79d0-4926-a0c6-738de5304b09"},"source":["What we'll cover:\n","- StrOutputParser ‚Äî plain text\n","- CommaSeparatedListOutputParser ‚Äî lists from simple text\n","- JsonOutputParser ‚Äî validated JSON objects\n","- PydanticOutputParser ‚Äî strongly typed objects\n","- Fixing bad outputs with an ‚Äúauto-repair‚Äù parser"]},{"cell_type":"markdown","source":["## Bootstrap"],"metadata":{"id":"-r-3rhCKPqf8"},"id":"-r-3rhCKPqf8"},{"cell_type":"markdown","source":["‚öì--- Before proceeding futher it is very important you do the following: --- üëæ\n","\n","Select the üóù (key) icon in the left pane and include your OpenAI Api key with Name as \"OPENAPI_KEY\" and value as the key, and grant it notebook access in order to be able to run this notebook."],"metadata":{"id":"YP3P3V-9L9F8"},"id":"YP3P3V-9L9F8"},{"cell_type":"markdown","metadata":{"id":"aeddf0b2-fc6a-4479-8d39-6dfaa715bef9"},"source":["Run the below two cells in the order they are in, before running further cells. Wait till a number appears in place of '*' or '[ ]'. Below the cell you should see \"Ready. LangChain + OpenAI set up.\""],"id":"aeddf0b2-fc6a-4479-8d39-6dfaa715bef9"},{"cell_type":"code","source":["!pip install -q langchain langchain-openai langchain-community pydantic pypdf faiss-cpu"],"metadata":{"id":"V37607__LK8B"},"execution_count":null,"outputs":[],"id":"V37607__LK8B"},{"cell_type":"code","execution_count":null,"id":"5d1490c1-bcb9-407f-adca-1333814d2020","metadata":{"id":"5d1490c1-bcb9-407f-adca-1333814d2020"},"outputs":[],"source":["# Environment & imports\n","import json\n","from google.colab import userdata\n","\n","key = userdata.get('OPENAI_API_KEY')  # returns None if not granted\n","if not key:\n","    raise RuntimeError(\"Set OPENAI_API_KEY in a .env file next to this notebook.\")\n","\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, CommaSeparatedListOutputParser\n","from langchain_core.runnables import RunnableLambda\n","\n","# (For Pydantic-based parsing)\n","from pydantic import BaseModel, Field\n","from langchain.output_parsers import PydanticOutputParser  # keep this import; it‚Äôs the common one\n","\n","# Model (small & fast). We‚Äôll enable streaming only when useful.\n","llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, api_key=key)\n","print(\"‚úÖ Ready: Output Parsers tutorial\")"]},{"cell_type":"markdown","id":"40b86c0b-c9b2-49bd-b5cb-a1c6f33de1f0","metadata":{"id":"40b86c0b-c9b2-49bd-b5cb-a1c6f33de1f0"},"source":["## StrOutputParser - The simplest one"]},{"cell_type":"markdown","id":"50f5eb50-a6a1-461f-9ebd-86806e43f55f","metadata":{"id":"50f5eb50-a6a1-461f-9ebd-86806e43f55f"},"source":["A string parser is often enough when you just need clean text without role metadata."]},{"cell_type":"code","execution_count":null,"id":"29992a87-ed7e-466f-9589-dcbf0bd73186","metadata":{"id":"29992a87-ed7e-466f-9589-dcbf0bd73186"},"outputs":[],"source":["prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Answer concisely in one sentence.\"),\n","    (\"user\", \"Summarize: {text}\")\n","])\n","\n","chain = prompt | llm | StrOutputParser()\n","\n","text = \"LangChain lets you compose LLM apps using prompts, models, tools, and chains.\"\n","result = chain.invoke({\"text\": text})\n","\n","print(\"\\n--- Final Output (str) ---\")\n","print(result)"]},{"cell_type":"markdown","id":"aa1bed01-00ad-4609-a158-9b5e90c18216","metadata":{"id":"aa1bed01-00ad-4609-a158-9b5e90c18216"},"source":["## CommaSeparatedListOutputParser"]},{"cell_type":"markdown","id":"6cf20ed7-63e0-49d5-a59e-4ec457cf47ee","metadata":{"id":"6cf20ed7-63e0-49d5-a59e-4ec457cf47ee"},"source":["Returns a list of comma separated values. This can be helpful when you want structured data not as JSON but as something as simple as a CSV. When using OutputParsers other than StrOutputParser it is important to mention the output type or structure in the prompt."]},{"cell_type":"markdown","id":"a238667e-0d53-4429-b38e-bd0a73fde877","metadata":{"id":"a238667e-0d53-4429-b38e-bd0a73fde877"},"source":["You can check what happens as you remove the phrase \"comma-separated only\" in the prompt."]},{"cell_type":"code","execution_count":null,"id":"6ad1becd-3db0-44ed-af56-45e8de62ce39","metadata":{"id":"6ad1becd-3db0-44ed-af56-45e8de62ce39"},"outputs":[],"source":["list_parser = CommaSeparatedListOutputParser()\n","\n","kw_prompt = PromptTemplate.from_template(\n","    \"From the following text, extract exactly 5 short keywords, comma-separated only.\\n\\nText: {text}\\n\"\n",")\n","\n","kw_chain = kw_prompt | llm | list_parser\n","\n","keywords = kw_chain.invoke({\n","    \"text\": \"LangChain enables composition of LLM apps; LCEL provides piping; tools and retrievers add capabilities.\"\n","})\n","\n","print(\"\\n--- Final Output (list) ---\")\n","print(keywords)      # a Python list of 5 strings\n","print(\"count:\", len(keywords))"]},{"cell_type":"markdown","id":"e177366c-ae30-4cca-b74a-30b951fabfa4","metadata":{"id":"e177366c-ae30-4cca-b74a-30b951fabfa4"},"source":["## JsonOutputParser"]},{"cell_type":"markdown","id":"f1540915-eee6-42de-b6c0-6f0d05ea8327","metadata":{"id":"f1540915-eee6-42de-b6c0-6f0d05ea8327"},"source":["Well, use this when you need a JSON or a dictionary with key-value pairs"]},{"cell_type":"code","execution_count":null,"id":"36f50202-0bdb-4c5c-8e1c-9df263ad07a5","metadata":{"id":"36f50202-0bdb-4c5c-8e1c-9df263ad07a5"},"outputs":[],"source":["json_parser = JsonOutputParser()\n","\n","# 1) Define the schema and ask the model to return the exact JSON structure\n","schema_instructions = \"\"\"Return a strict JSON object with keys:\n","- \"name\": string\n","- \"category\": string\n","- \"price\": number\n","- \"features\": array of strings (3 items)\n","No extra commentary or fields. Only the JSON.\n","\"\"\"\n","\n","product_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You produce strictly formatted JSON responses.\"), # Instruct llm to return JSON response.\n","    (\"user\", \"{schema}\\n\\nMake a synthetic product card for: {topic}\")\n","])\n","\n","product_chain = (\n","    {\"schema\": RunnableLambda(lambda x: schema_instructions), \"topic\": RunnableLambda(lambda x: x[\"topic\"])}\n","    | product_prompt\n","    | llm\n","    | json_parser\n",")\n","\n","product = product_chain.invoke({\"topic\": \"a lightweight running shoe\"})\n","print(\"\\n--- Final Output (dict) ---\")\n","print(json.dumps(product, indent=2))\n","print(\"type:\", type(product))"]},{"cell_type":"markdown","id":"20e00610-0295-451b-8fda-dc5d8609757f","metadata":{"id":"20e00610-0295-451b-8fda-dc5d8609757f"},"source":["## Pydantic Objects and PydanticOutputParser"]},{"cell_type":"markdown","id":"951e7209-1f75-4b02-9a15-5f8c17163807","metadata":{"id":"951e7209-1f75-4b02-9a15-5f8c17163807"},"source":["Define a Pydantic model and parse the model output directly into a validated Python object. Pydantic models are similar to POJO (Plain Old Javascript Objects) or Typescript or Javascript objects with type hinting."]},{"cell_type":"markdown","id":"9baf3667-25ca-48f2-af82-78cd352f3a53","metadata":{"id":"9baf3667-25ca-48f2-af82-78cd352f3a53"},"source":["We create a `PydanticOutputParser` with the `pydantic_object` as the object on which the output should be modelled after.\n","\n","`get_format_instructions()` on the resultant object returns formatting instructions for JSON type with the JSON schema modelled after the Pydantic model.\n","\n","In the result, we can use `.model_dump` to convert the Pydantic object into JSON output."]},{"cell_type":"code","execution_count":null,"id":"7c0b8898-d5f6-4ec6-9689-eaa46a29f0dc","metadata":{"id":"7c0b8898-d5f6-4ec6-9689-eaa46a29f0dc"},"outputs":[],"source":["# 1) Define your target schema\n","class Ticket(BaseModel):\n","    title: str = Field(..., description=\"Short title of the user's issue\")\n","    urgency: str = Field(..., description=\"One of: low, medium, high\")\n","    tags: list[str] = Field(..., description=\"Relevant tags (2-5)\")\n","\n","ticket_parser = PydanticOutputParser(pydantic_object=Ticket)\n","\n","# 2) Provide parser instructions to the model (helps it format correctly)\n","format_instructions = ticket_parser.get_format_instructions()\n","\n","ticket_prompt = PromptTemplate.from_template(\n","    \"Read the user's request and produce a ticket.\\n\"\n","    \"{format_instructions}\\n\\n\"\n","    \"User request: {request}\"\n",")\n","\n","# 3) Prompt ‚Üí Model ‚Üí Pydantic object\n","ticket_chain = (\n","    {\"format_instructions\": RunnableLambda(lambda _: format_instructions),\n","     \"request\": RunnableLambda(lambda x: x[\"request\"])}\n","    | ticket_prompt\n","    | llm\n","    | ticket_parser\n",")\n","\n","ticket = ticket_chain.invoke({\"request\": \"The dashboard times out when I export to CSV. Need a fix ASAP.\"})\n","print(\"\\n--- Final Output (Ticket model) ---\")\n","print(ticket)\n","print(\"type:\", type(ticket))\n","print(\"ticket.urgency:\", ticket.urgency)"]},{"cell_type":"markdown","id":"26a4e732-a384-4f48-937d-862fc64031ed","metadata":{"id":"26a4e732-a384-4f48-937d-862fc64031ed"},"source":["Here, use `.model_dump` on ticket to convert the Pydantic output to JSON."]},{"cell_type":"markdown","id":"86571a13-1e7c-4198-9c69-16139377da6d","metadata":{"id":"86571a13-1e7c-4198-9c69-16139377da6d"},"source":["## Repairing invalid outputs (auto-fix pass)"]},{"cell_type":"markdown","id":"f9f1c6cf-e292-4f5a-a895-89baccbfc615","metadata":{"id":"f9f1c6cf-e292-4f5a-a895-89baccbfc615"},"source":["Models sometimes return malformed JSON or miss fields. A common pattern is to repair the output by prompting the model again with the parsing error and asking it to fix the format."]},{"cell_type":"code","execution_count":null,"id":"e7f0f108-1e37-4f03-aff6-965491c76a0c","metadata":{"id":"e7f0f108-1e37-4f03-aff6-965491c76a0c"},"outputs":[],"source":["from langchain.output_parsers import OutputFixingParser  # helper that uses the model to repair\n","\n","# Base parser we want to enforce\n","base_parser = JsonOutputParser()\n","\n","# Wrapper that will try to fix invalid outputs using the same llm\n","fixing_parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm)\n","\n","bad_json_prompt = PromptTemplate.from_template(\n","    \"Return a JSON object with keys 'a' (int) and 'b' (int) only, no comments.\\n\"\n","    \"If you include any text other than JSON, you'll be asked to fix it.\\n\"\n","    \"Task: {task}\"\n",")\n","\n","strict_json_chain = bad_json_prompt | llm | fixing_parser\n","\n","# Even if the model returns extra words, the fixing parser tries to repair it.\n","data = strict_json_chain.invoke({\"task\": \"produce small integers for a and b\"})\n","print(\"\\n--- Final Output (repaired dict) ---\")\n","print(data, type(data))"]},{"cell_type":"markdown","id":"0321ed84-94ad-4be2-88e9-f758f2c70849","metadata":{"id":"0321ed84-94ad-4be2-88e9-f758f2c70849"},"source":["## How it works\n","\n","1. OutputFixingParser wraps a base parser (like JsonOutputParser).\n","2. If parsing fails, it sends the error + original text back to the model to produce a corrected version.\n","3. You get a best-effort repaired result (still validate downstream if critical)."]},{"cell_type":"markdown","id":"234c2e83-c69a-4f32-bf2a-9b75fd3467ef","metadata":{"id":"234c2e83-c69a-4f32-bf2a-9b75fd3467ef"},"source":["## Here's a complete chain with structured output"]},{"cell_type":"code","execution_count":null,"id":"7f7c2e8f-0aad-4d00-960d-705f393df4e8","metadata":{"id":"7f7c2e8f-0aad-4d00-960d-705f393df4e8"},"outputs":[],"source":["meetups_schema = \"\"\"\n","Return a JSON object:\n","{\n","  \"city\": string,\n","  \"events\": [\n","    {\"title\": string, \"date\": string (ISO 8601), \"topic\": string}\n","  ]\n","}\n","Only the JSON. No commentary.\n","\"\"\"\n","\n","meetups_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a structured information extractor.\"),\n","    (\"user\", \"{schema}\\n\\nExtract from:\\n\\n{text}\")\n","])\n","\n","meetups_chain = (\n","    {\"schema\": RunnableLambda(lambda x: meetups_schema), \"text\": RunnableLambda(lambda x: x[\"text\"])}\n","    | meetups_prompt\n","    | llm\n","    | JsonOutputParser()\n",")\n","\n","sample = \"\"\"\n","Bangalore Python Guild meets on 2025-09-12 to discuss LangGraph patterns.\n","DataTalks meetup on 2025-10-03: topic is vector databases for production RAG.\n","\"\"\"\n","parsed = meetups_chain.invoke({\"text\": sample})\n","print(\"\\n--- Final Output (dict) ---\")\n","print(json.dumps(parsed, indent=2))\n","print(\"events count:\", len(parsed[\"events\"]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}