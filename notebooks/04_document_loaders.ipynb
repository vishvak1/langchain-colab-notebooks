{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5304f3da-a006-43e6-be32-9c648b5eac90",
      "metadata": {
        "id": "5304f3da-a006-43e6-be32-9c648b5eac90"
      },
      "source": [
        "# Document Loaders & Text Splitters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0820e7f-def8-4e8f-be50-d4b99f25052f",
      "metadata": {
        "id": "a0820e7f-def8-4e8f-be50-d4b99f25052f"
      },
      "source": [
        "- Document Loaders read raw sources (files, PDFs, web pages, DB rows, strings) into a uniform Document shape (page_content + metadata).\n",
        "- Text Splitters chunk long text into smaller, overlapping pieces that fit model context windows and improve retrieval quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038629cf-e93a-4a9c-86ef-95b76dd5952a",
      "metadata": {
        "id": "038629cf-e93a-4a9c-86ef-95b76dd5952a"
      },
      "source": [
        "What we'll cover:\n",
        "- Creating Documents (from strings and files)\n",
        "- Popular splitters (RecursiveCharacterTextSplitter, TokenTextSplitter, MarkdownHeaderTextSplitter)\n",
        "- Preserving metadata (page numbers, headers, source)\n",
        "- Choosing chunk size & overlap sensibly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrap"
      ],
      "metadata": {
        "id": "ppJTjfp2QIOL"
      },
      "id": "ppJTjfp2QIOL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓--- Before proceeding futher it is very important you do the following: --- 👾\n",
        "\n",
        "Select the 🗝 (key) icon in the left pane and include your OpenAI Api key with Name as \"OPENAPI_KEY\" and value as the key, and grant it notebook access in order to be able to run this notebook."
      ],
      "metadata": {
        "id": "YP3P3V-9L9F8"
      },
      "id": "YP3P3V-9L9F8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeddf0b2-fc6a-4479-8d39-6dfaa715bef9"
      },
      "source": [
        "Run the below cells in the order they are in, before running further cells. Wait till a number appears in place of '*' or '[ ]'. Below the cell you should see \"✅ Ready: Text Splitters and Document tutorial\""
      ],
      "id": "aeddf0b2-fc6a-4479-8d39-6dfaa715bef9"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vishvak1/langchain-colab-notebooks.git"
      ],
      "metadata": {
        "id": "MbNjX0dsXbPP"
      },
      "id": "MbNjX0dsXbPP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"langchain-colab-notebooks\")"
      ],
      "metadata": {
        "id": "chXISsbCXdVB"
      },
      "id": "chXISsbCXdVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-openai langchain-community pydantic pypdf"
      ],
      "metadata": {
        "id": "V37607__LK8B"
      },
      "execution_count": null,
      "outputs": [],
      "id": "V37607__LK8B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f84a42-67d9-4d66-9de7-47b4bb66605c",
      "metadata": {
        "id": "95f84a42-67d9-4d66-9de7-47b4bb66605c"
      },
      "outputs": [],
      "source": [
        "# No API keys required for this notebook.\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Loaders (community package)\n",
        "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
        "# (Optional) PDF example — uncomment if you have local PDFs\n",
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Text splitters\n",
        "from langchain_text_splitters import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    TokenTextSplitter,\n",
        "    MarkdownHeaderTextSplitter,\n",
        ")\n",
        "\n",
        "print(\"✅ Ready: Text Splitters and Document tutorial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe27cff7-b67f-45a7-a088-9edd1eb080d3",
      "metadata": {
        "id": "fe27cff7-b67f-45a7-a088-9edd1eb080d3"
      },
      "source": [
        "## What a Document looks like"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3be59ab7-f458-4836-ba8c-e6ac82b0cf41",
      "metadata": {
        "id": "3be59ab7-f458-4836-ba8c-e6ac82b0cf41"
      },
      "source": [
        "A document wraps text and metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e1a63a-3f96-46ae-b7ed-8cf8be205a40",
      "metadata": {
        "id": "30e1a63a-3f96-46ae-b7ed-8cf8be205a40"
      },
      "outputs": [],
      "source": [
        "# Create Documents by hand (great for demos/tests)\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"LangChain helps you compose LLM applications.\",\n",
        "        metadata={\"source\": \"notes\", \"topic\": \"langchain\", \"order\": 1}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"LCEL uses the | operator to connect runnables into chains.\",\n",
        "        metadata={\"source\": \"notes\", \"topic\": \"lcel\", \"order\": 2}\n",
        "    ),\n",
        "]\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27835a17-aa55-4057-8b30-f0449715ce10",
      "metadata": {
        "id": "27835a17-aa55-4057-8b30-f0449715ce10"
      },
      "source": [
        "1. Each document has page_content (string) and metadata (dict).\n",
        "2. Keep metadata meaningul (eg. section, page, url) as it will help in the data storage part later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c280374-7fe4-4337-a9cd-89fd3ac80c3e",
      "metadata": {
        "id": "9c280374-7fe4-4337-a9cd-89fd3ac80c3e"
      },
      "source": [
        "## Loading from files (Plain text or PDFs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d36cfe-6e37-4cd4-9f18-e64d77f70126",
      "metadata": {
        "id": "a3d36cfe-6e37-4cd4-9f18-e64d77f70126"
      },
      "source": [
        "Here's an example of a simple text file loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c774043-693b-4b90-8a23-d47f489f9362",
      "metadata": {
        "id": "8c774043-693b-4b90-8a23-d47f489f9362"
      },
      "outputs": [],
      "source": [
        "# Save a sample file once (for demo)\n",
        "sample_path = \"data/sample_notes.txt\"\n",
        "with open(sample_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"Line 1: LCEL composes steps with pipes.\\n\")\n",
        "    f.write(\"Line 2: Text splitters break large text into chunks with overlap.\\n\")\n",
        "\n",
        "# Load the text file into Documents\n",
        "loader = TextLoader(sample_path, encoding=\"utf-8\")\n",
        "file_docs = loader.load()\n",
        "\n",
        "file_docs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f351bab-9be8-421e-9bcb-061894c9f8cb",
      "metadata": {
        "id": "7f351bab-9be8-421e-9bcb-061894c9f8cb"
      },
      "source": [
        "Using PyPDFLoader you can load PDFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93dd410-c564-45ec-b98e-cab5c4b6e623",
      "metadata": {
        "id": "c93dd410-c564-45ec-b98e-cab5c4b6e623"
      },
      "outputs": [],
      "source": [
        "# Uncomment if you have a local PDF path\n",
        "pdf_loader = PyPDFLoader(\"data/my_file.pdf\")\n",
        "pdf_docs = pdf_loader.load()  # one Document per page with metadata[\"page\"]\n",
        "pdf_docs[0], pdf_docs[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0193f1ae-e003-477a-a343-a795f398da6e",
      "metadata": {
        "id": "0193f1ae-e003-477a-a343-a795f398da6e"
      },
      "source": [
        "- `TextLoader` -> for loading simple text files\n",
        "- `PyPDFLoader` -> for loading documents in the form of Pdfs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90eebb6-2ed0-4179-827d-cd9318bc1c19",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "a90eebb6-2ed0-4179-827d-cd9318bc1c19"
      },
      "source": [
        "## The workhorse aka RecursiveCharacterSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deed6470-e5a5-48a6-82d7-5d4fd5b97cfe",
      "metadata": {
        "id": "deed6470-e5a5-48a6-82d7-5d4fd5b97cfe"
      },
      "source": [
        "The `RecursiveCharacterTextSplitter` splits a large text into smaller chunks by trying a list of separators such as `\\n`, `\\n\\n`, ` ` in a specific order. It's designed to keep semantically related pieces of text together as much as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c964142-4446-4749-b5d7-fb069283b839",
      "metadata": {
        "id": "9c964142-4446-4749-b5d7-fb069283b839"
      },
      "source": [
        "The goal is to create text chunks smaller than a specified `chunk_size`. This is helpful when you have a document you'd like to split into chunks and create vector embeddings for those chunks to create a RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf4aba3-7b84-4b1a-938f-619a50ca3efd",
      "metadata": {
        "id": "baf4aba3-7b84-4b1a-938f-619a50ca3efd"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,        # target chars per chunk\n",
        "    chunk_overlap=40,      # overlap helps keep context continuity\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # try big → small units\n",
        "    length_function=len    # length in characters (default)\n",
        ")\n",
        "\n",
        "split_docs = text_splitter.split_documents(pdf_docs) # You can switch this file_docs if pdf_docs doesn't work for you\n",
        "# Comment the above lien and uncomment the below line if you have a pdf loaded as mentioned in the previous cell\n",
        "# split_docs = text_splitter.split_documents(pdf_docs)\n",
        "len(split_docs), split_docs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bcf34f-b06f-4ea6-8d15-cbe4d49a35c1",
      "metadata": {
        "id": "64bcf34f-b06f-4ea6-8d15-cbe4d49a35c1"
      },
      "source": [
        "### How it works?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfa2882-81d4-4703-8069-1c978e78c06c",
      "metadata": {
        "id": "2cfa2882-81d4-4703-8069-1c978e78c06c"
      },
      "source": [
        "1. Takes the wholes text\n",
        "2. It tries to split the text using the first separator in its list (by default, this is a double newline: \"\\n\\n\"). This attempts to split the text into paragraphs.\n",
        "3. After splitting, it looks at the resulting list of text chunks.\n",
        "4. If a created chunk is smaller than the desired `chunk_size` it is added to the output.\n",
        "5. If the chunk is bigger than the `chunk_size`, recursively tries the next splitter `/n` on that chunk and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d14176-9e50-4e3b-b99d-4cbd469b66f8",
      "metadata": {
        "id": "99d14176-9e50-4e3b-b99d-4cbd469b66f8"
      },
      "source": [
        "## Token aware splitting - TokenTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fecf010f-54ef-4999-8daa-c9a394b806fd",
      "metadata": {
        "id": "fecf010f-54ef-4999-8daa-c9a394b806fd"
      },
      "source": [
        "When working with models with strict token limits, split by tokens instead of characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbf52ff-92b7-4d13-a325-29c52e506e90",
      "metadata": {
        "id": "4bbf52ff-92b7-4d13-a325-29c52e506e90"
      },
      "outputs": [],
      "source": [
        "tok_splitter = TokenTextSplitter(\n",
        "    chunk_size=120,     # roughly 120 tokens\n",
        "    chunk_overlap=20,   # in tokens\n",
        "    encoding_name=\"cl100k_base\"  # good default for many OpenAI models\n",
        ")\n",
        "\n",
        "token_docs = tok_splitter.split_documents(pdf_docs) # You can switch this to file_docs if pdf_docs doesn't work for you.\n",
        "len(token_docs), token_docs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a7dbbc-7630-467e-a93d-26b38849398a",
      "metadata": {
        "id": "c4a7dbbc-7630-467e-a93d-26b38849398a"
      },
      "source": [
        "### How it works"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f944722-2cfc-4893-9270-4f6b73242e18",
      "metadata": {
        "id": "7f944722-2cfc-4893-9270-4f6b73242e18"
      },
      "source": [
        "1. Uses tokenizer estimates (via tiktoken) to count tokens.\n",
        "2. Keep chunks well under your model’s max context to leave room for prompt + response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "918707f1-5c75-4fd0-b37b-1a06eddb14c2",
      "metadata": {
        "id": "918707f1-5c75-4fd0-b37b-1a06eddb14c2"
      },
      "source": [
        "## MarkdownHeaderTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ad488d-e718-4807-98ef-812288e37b32",
      "metadata": {
        "id": "d5ad488d-e718-4807-98ef-812288e37b32"
      },
      "source": [
        "Markdown docs often have section headers. This splitter preserves headers in metadata so you can filter or display section-aware results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "161dd1e1-a626-48df-b545-63ae0653d205",
      "metadata": {
        "id": "161dd1e1-a626-48df-b545-63ae0653d205"
      },
      "source": [
        "This is usually paired with other splitters to limit `chunk_size` or token limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cad032d-e06b-4625-949c-39090fd8094b",
      "metadata": {
        "id": "1cad032d-e06b-4625-949c-39090fd8094b"
      },
      "outputs": [],
      "source": [
        "markdown_text = \"\"\"# Project Alpha\n",
        "\n",
        "Intro paragraph about Alpha.\n",
        "\n",
        "## Features\n",
        "- Fast startup\n",
        "- Modular design\n",
        "\n",
        "## Architecture\n",
        "The system consists of a frontend, backend, and vector store.\n",
        "\n",
        "### Backend\n",
        "Uses Python and FastAPI.\n",
        "\n",
        "### Vector Store\n",
        "FAISS in-memory for development; switchable later.\n",
        "\"\"\"\n",
        "\n",
        "# First: split into sections by headers and carry header paths in metadata\n",
        "md_header_splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=[\n",
        "        (\"#\", \"h1\"),\n",
        "        (\"##\", \"h2\"),\n",
        "        (\"###\", \"h3\"),\n",
        "    ]\n",
        ")\n",
        "md_sections = md_header_splitter.split_text(markdown_text)\n",
        "\n",
        "# You now have Documents with metadata like {\"h1\": \"...\", \"h2\": \"...\"}\n",
        "md_sections[:3], md_sections[0].metadata\n",
        "\n",
        "# Second: optionally run a character/token splitter to limit chunk size\n",
        "md_chunker = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
        "md_chunks = md_chunker.split_documents(md_sections)\n",
        "\n",
        "len(md_chunks), md_chunks[:2]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}